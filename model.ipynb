{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e07b3aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\soham\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    LayoutLMv3Tokenizer,\n",
    "    LayoutLMv3ForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7d89fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\soham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80aa4b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07508587de50447aac80856a380c271f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IterableDatasetDict({\n",
      "    train: IterableDataset({\n",
      "        features: ['image', 'bboxes', 'category_id', 'segmentation', 'area', 'pdf_cells', 'metadata'],\n",
      "        num_shards: 29\n",
      "    })\n",
      "    test: IterableDataset({\n",
      "        features: ['image', 'bboxes', 'category_id', 'segmentation', 'area', 'pdf_cells', 'metadata'],\n",
      "        num_shards: 2\n",
      "    })\n",
      "    val: IterableDataset({\n",
      "        features: ['image', 'bboxes', 'category_id', 'segmentation', 'area', 'pdf_cells', 'metadata'],\n",
      "        num_shards: 3\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"ds4sd/DocLayNet-v1.1\", streaming=True)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e87b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label map and categories of interest\n",
    "label_map = {\n",
    "    1: \"Caption\",\n",
    "    2: \"Footnote\",\n",
    "    3: \"Formula\",\n",
    "    4: \"List-item\",\n",
    "    5: \"Page-footer\",\n",
    "    6: \"Page-header\",\n",
    "    7: \"Picture\",\n",
    "    8: \"Section-header\",\n",
    "    9: \"Table\",\n",
    "    10: \"Text\",\n",
    "    11: \"Title\"\n",
    "}\n",
    "categories_of_interest = [1, 8, 10, 11]\n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    texts = []\n",
    "    bboxes = []\n",
    "    category_ids = []\n",
    "    \n",
    "    # Extract text cells from pdf_cells\n",
    "    for cell_list in sample['pdf_cells']:\n",
    "        if isinstance(cell_list, dict):\n",
    "            cell_list = [cell_list]\n",
    "        for cell in cell_list:\n",
    "            cell_bbox = cell['bbox']\n",
    "            cell_text = cell['text'].strip() if isinstance(cell['text'], str) else \"\"\n",
    "            if not cell_text:\n",
    "                continue\n",
    "\n",
    "            # Match text cell to annotated objects\n",
    "            matched_category_id = -1\n",
    "            for obj_bbox, obj_cat_id in zip(sample['bboxes'], sample['category_id']):\n",
    "                if is_overlapping(cell_bbox, obj_bbox):\n",
    "                    matched_category_id = obj_cat_id\n",
    "                    break\n",
    "\n",
    "            texts.append(cell_text)\n",
    "            bboxes.append(cell_bbox)\n",
    "            category_ids.append(matched_category_id)\n",
    "\n",
    "    return {\n",
    "        \"texts\": texts,\n",
    "        \"bboxes\": bboxes,\n",
    "        \"category_ids\": category_ids\n",
    "    }\n",
    "\n",
    "def is_overlapping(bbox1, bbox2):\n",
    "    x1, y1, w1, h1 = bbox1\n",
    "    x2, y2, w2, h2 = bbox2\n",
    "    return (x1 < x2 + w2 and x1 + w1 > x2 and y1 < y2 + h2 and y1 + h1 > y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b01d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = ds['train']\n",
    "# ds1 = train_dataset.take(1)\n",
    "# print(ds1)\n",
    "# for index, sample in enumerate(ds1):\n",
    "#     out = sample\n",
    "#     output = preprocess_sample(sample)\n",
    "#     print(output)\n",
    "# a = preprocess_sample(out)\n",
    "# for x in a:\n",
    "#     print(a[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3adaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = LayoutLMv3Tokenizer.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "\n",
    "def normalize_bbox(bbox, width=1000, height=1000):\n",
    "    x, y, w, h = bbox\n",
    "    return [\n",
    "        int(1000 * x / width),\n",
    "        int(1000 * y / height),\n",
    "        int(1000 * (x + w) / width),\n",
    "        int(1000 * (y + h) / height)\n",
    "    ]\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"bbox\": [],\n",
    "        \"labels\": [],\n",
    "        \"category_ids\": []\n",
    "    }\n",
    "    \n",
    "    for text, bbox, category_id in zip(\n",
    "        examples['texts'], examples['bboxes'], examples['category_ids']\n",
    "    ):\n",
    "        if not isinstance(text, str):\n",
    "            logger.warning(f\"Skipping invalid text: {text} (type: {type(text)})\")\n",
    "            continue\n",
    "        \n",
    "        if not text.strip() or text.strip() in [\",\", \";\"]:\n",
    "            logger.warning(f\"Skipping empty or invalid text: {text}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            words = nltk.word_tokenize(text)\n",
    "            norm_bbox = normalize_bbox(bbox)\n",
    "            word_bboxes = [norm_bbox for _ in words]\n",
    "            encoding = tokenizer(\n",
    "                words,\n",
    "                boxes=word_bboxes,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\",\n",
    "                is_split_into_words=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Tokenization failed for text: {text}, error: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        token_bboxes = [norm_bbox for _ in range(len(encoding['input_ids'][0]))]\n",
    "        \n",
    "        # Assign label: 0 (Caption), 1 (Section-header), 2 (Text), 3 (Title), 4 (Other)\n",
    "        if category_id == 1:\n",
    "            label = 0\n",
    "        elif category_id == 8:\n",
    "            label = 1\n",
    "        elif category_id == 10:\n",
    "            label = 2\n",
    "        elif category_id == 11:\n",
    "            label = 3\n",
    "        else:\n",
    "            label = 4\n",
    "        \n",
    "        tokenized_inputs['input_ids'].append(encoding['input_ids'][0])\n",
    "        tokenized_inputs['attention_mask'].append(encoding['attention_mask'][0])\n",
    "        tokenized_inputs['bbox'].append(token_bboxes)\n",
    "        tokenized_inputs['labels'].append(label)\n",
    "        tokenized_inputs['category_ids'].append(category_id)\n",
    "    \n",
    "    return tokenized_inputs\n",
    "\n",
    "def process_dataset(dataset, num_samples=100):\n",
    "    processed_data = {\n",
    "        \"texts\": [],\n",
    "        \"bboxes\": [],\n",
    "        \"category_ids\": []\n",
    "    }\n",
    "    for i, sample in enumerate(dataset.take(num_samples)):\n",
    "        try:\n",
    "            result = preprocess_sample(sample)\n",
    "            processed_data['texts'].extend(result['texts'])\n",
    "            processed_data['bboxes'].extend(result['bboxes'])\n",
    "            processed_data['category_ids'].extend(result['category_ids'])\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing sample {i}: {str(e)}\")\n",
    "            continue\n",
    "    return tokenize_and_align_labels(processed_data)\n",
    "\n",
    "def create_dataset(tokenized_data):\n",
    "    return Dataset.from_dict({\n",
    "        'input_ids': tokenized_data['input_ids'],\n",
    "        'attention_mask': tokenized_data['attention_mask'],\n",
    "        'bbox': tokenized_data['bbox'],\n",
    "        'labels': tokenized_data['labels'],\n",
    "        'category_ids': tokenized_data['category_ids']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146059c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'texts': ['NOTES TO THE FINANCIAL STATEMENTS', 'Finance receivables that originated outside the U.S. were $52.7 billion and $47.5 billion at December 31, 2004 and 2003,', 'respectively. Other finance receivables consisted primarily of real estate, commercial and other collateralized loans and', 'accrued interest.', 'Included in net finance and other receivables at December 31, 2004 and 2003 were $16.9 billion and $14.3 billion,', 'respectively, of receivables that have been sold for legal purposes to consolidated securitization SPEs and are available only', 'for repayment of debt issued by those entities, and to pay other securitization investors and other participants; they are not', 'available to pay our other obligations or the claims of our other creditors.', 'Future maturities, exclusive of the effects of SFAS No. 133,', 'Accounting for Derivative Instruments and Hedging Activities', ', of', 'total finance receivables including minimum lease rentals are as follows (in billions): 2005 - $64.7; 2006 - $24.3;', '2007 - $13.9; thereafter - $10.1. Experience indicates that a substantial portion of the portfolio generally is repaid before', 'the contractual maturity dates.', 'Finance receivables subject to fair value at December 31, 2004 and 2003 were $106.2 billion and $102.0 billion,', 'respectively. The fair value of these finance receivables at December 31, 2004 and 2003 was $106.4 billion and', '$103.8 billion, respectively.', 'Included in retail receivables above are investments in direct financing leases. The net investment at December 31 was as', 'follows (in millions):', 'The investment in direct financing leases relates to the leasing of vehicles, various types of transportation and other equipment', 'and facilities. Future maturities of minimum lease rentals, as included above, are as follows (in billions): 2005 - $2.1;', '2006 - $1.5; 2007 - $1; thereafter - $0.4.', 'The net investment in operating leases at December 31 was as follows (in millions):', 'Included in net investment in operating leases at December 31, 2004 were interests in operating leases and the related vehicles', 'of about $2.5 billion that have been transferred for legal purposes to consolidated securitization SPEs and are available only', 'for repayment of debt issued by those entities, and to pay other securitization investors and other participants; they are not', 'available to pay our other obligations or the claims of our other creditors.', 'Minimum rentals on operating leases are contractually due as follows:', '2005 - $4.7 billion; 2006 - $2.2 billion;', '2007 - $1.3 billion; 2008 - $548 million; 2009 - $135 million; thereafter - $407 million.', 'Assets subject to operating leases are depreciated primarily on the straight-line method over the term of the lease to reduce', 'the asset to its estimated residual value. Estimated residual values are based on assumptions for used vehicle prices at lease', 'termination and the number of vehicles that are expected to be returned. Operating lease depreciation expense (which includes', 'gains and losses on disposal of assets) was $6.4 billion in 2004, $8.5 billion in 2003, and $9.9 billion in 2002.', '7', '1', 'NOTE 11. NET INVESTMENT IN OPERATING LEASES – FINANCIAL SERVICES SECTOR', 'follows (in millions):', '2004', '2003', 'Total minimum lease rentals to be received', '$', '4,972', '$', '5,532', 'Less:', 'Unearned income', '(758)', '(972)', 'Loan origination costs', '50', '42', 'Estimated residual values', '3,367', '4,017', 'Less:', 'Allowance for credit losses', '(82)', '(139)', 'Net investment in direct financing leases', '$', '7,549', '$', '8,480', '2004', '2003', 'Vehicles and other equipment, at cost', '$', '41,545', '$', '44,098', 'Accumulated depreciation', '(9,477)', '(11,615)', 'Allowances for credit losses', '(305)', '(624)', 'Net investment in operating leases', '$', '31,763', '$', '31,859'], 'bboxes': [[72.35294285130719, 55.47565740740731, 372.2156845996732, 20.452899744572278], [100.1946343137255, 117.51495402298849, 789.325354248366, 14.880172413793161], [100.1946343137255, 131.26016475095776, 758.9220286764706, 14.880172413793275], [100.1946343137255, 145.00537547892714, 108.22794452614379, 14.880172413793161], [100.1946343137255, 166.60499233716473, 747.6320053921569, 14.880172413793161], [100.1946343137255, 180.350203065134, 787.606971895425, 14.880172413793275], [100.1946343137255, 194.09541379310338, 779.7687533496731, 14.880172413793275], [100.1946343137255, 207.84062452107275, 465.5911630718954, 14.880172413793161], [100.1946343137255, 229.44024137931035, 374.5018415849674, 14.880172413793161], [474.6881854575164, 229.44024137931035, 382.9580882352941, 15.221825989782928], [857.6399260620916, 229.44024137931035, 25.353676470588084, 14.880172413793161], [100.1946343137255, 243.18545210727962, 715.3503505718954, 14.880172413793275], [100.1946343137255, 256.930662835249, 768.6491446895426, 14.880172413793161], [100.1946343137255, 270.6758735632184, 195.1418983660131, 14.880172413793161], [100.1946343137255, 292.27549042145586, 733.4930013071895, 14.880172413793275], [100.1946343137255, 306.02070114942524, 709.7969441176471, 14.880172413793161], [100.1946343137255, 319.7659118773946, 175.86285424836598, 14.880172413793161], [100.1946343137255, 341.3655287356321, 757.4533644607844, 14.880172413793161], [100.1946343137255, 355.11077873563215, 125.03492982026144, 14.880133141762485], [100.1946343137255, 500.4172921455938, 798.3091945261439, 14.880133141762485], [100.1946343137255, 514.1625028735632, 734.293154493464, 14.880133141762428], [100.1946343137255, 527.9077136015326, 260.7323685457516, 14.880133141762428], [100.1946343137255, 587.1456184546616, 523.0514906862745, 14.880146232439358], [100.1946343137255, 704.9616973180077, 808.544070751634, 14.880172413793105], [100.1946343137255, 718.706908045977, 794.0132386437908, 14.880172413793105], [100.1946343137255, 732.4521187739464, 779.7687533496731, 14.880172413793048], [100.1946343137255, 746.1973295019156, 465.5911630718954, 14.880172413793105], [100.1946343137255, 767.7969463601532, 453.12813447712426, 14.880172413793105], [568.9824407679739, 767.7969463601532, 232.7809836601307, 14.880172413793105], [100.1946343137255, 781.5421570881226, 571.5882218954249, 14.880172413793076], [100.1946343137255, 803.141787037037, 781.8036128267973, 14.880185504470006], [100.1946343137255, 816.8869977650064, 783.1903942810459, 14.880185504469978], [100.1946343137255, 830.6322084929757, 809.4785960784315, 14.880185504469978], [100.1946343137255, 844.3774192209451, 713.8220621732027, 14.880185504469978], [947.1874599673203, 987.4297167624521, 7.058967320261559, 16.533526213282247], [965.2760804738563, 987.4297167624521, 5.459682598039194, 16.533526213282247], [100.1946343137255, 563.0967359514686, 709.1827815359477, 18.74849361430398], [100.1946343137255, 355.11077873563215, 125.03492982026144, 14.880133141762485], [717.8631883169935, 373.0684252873564, 34.85003349673195, 14.91554342273298], [842.7994669117647, 373.1509227330779, 34.85008374182996, 14.880146232439415], [100.1945204248366, 387.2888014048532, 267.2386029411765, 14.880133141762371], [693.2798696895425, 387.2888014048532, 8.712499999999977, 14.880133141762371], [736.1336793300653, 387.20630395913156, 39.2062332516341, 14.915530332056164], [820.7991482843138, 387.2888014048532, 10.49087499999996, 14.880133141762371], [861.0753676470589, 387.2888014048532, 39.206149509803936, 14.880133141762371], [117.23287602124184, 401.4267586206896, 34.37500126633985, 14.880133141762485], [168.6462982026144, 401.4267586206896, 95.26175816993464, 14.880133141762485], [744.6555159313726, 401.344261174968, 34.3073696895425, 14.915530332056278], [868.9588737745099, 401.4267586206896, 34.94034068627445, 14.880133141762485], [100.19446850490196, 415.56471583652615, 138.08860461601313, 14.880133141762485], [757.9202385620915, 415.48221839080463, 17.424999999999955, 14.915530332056164], [882.8566176470588, 415.56471583652615, 17.42489950980405, 14.880133141762485], [100.19446850490196, 429.7026730523627, 158.48308991013073, 14.880133141762485], [736.1389885620915, 429.62017560664117, 39.206249999999955, 14.915530332056164], [861.0753676470589, 429.7026730523627, 39.206149509803936, 14.880133141762485], [114.14877998366013, 443.8405779054917, 28.152824183006558, 14.880146232439301], [156.25592234477122, 443.8405779054917, 163.63523901143796, 14.880146232439301], [754.7848774509805, 443.7580804597701, 25.594886437908485, 14.915543422733094], [870.3755008169935, 443.8405779054917, 34.94054166666672, 14.880146232439301], [100.19435294117648, 457.9784565772669, 253.62722263071896, 14.880133141762485], [693.2796687091503, 457.9784565772669, 8.712500000000091, 14.880133141762485], [736.1335118464053, 457.8959591315454, 39.206249999999955, 14.915530332056164], [820.7988970588235, 457.9784565772669, 10.490875000000074, 14.880133141762485], [861.0751666666666, 457.9784565772669, 39.20613276143797, 14.880133141762485], [713.1505665849674, 610.2406749680715, 34.85001674836599, 14.915530332056221], [839.4756531862745, 610.3231724137931, 34.84998325163406, 14.880133141762485], [100.1941368872549, 624.4610772669221, 235.99117479575165, 14.880146232439358], [693.4438361928105, 624.4610772669221, 8.712499999999977, 14.880146232439358], [726.3175625, 624.3785798212004, 37.47426797385617, 14.915543422733094], [825.4821756535948, 624.4610772669221, 6.316512254901909, 14.880146232439358], [850.9106335784313, 624.4610772669221, 39.208176062091525, 14.880146232439358], [100.1941368872549, 638.5990344827586, 165.41691008986925, 14.880146232439358], [720.0352504084967, 638.5165370370371, 47.37606944444451, 14.915543422733094], [848.6485155228759, 638.5990344827586, 45.08800816993448, 14.880146232439358], [100.1941368872549, 652.7369524265645, 174.2801453839869, 14.880133141762485], [732.832660130719, 652.654454980843, 34.3073696895425, 14.915530332056221], [858.524675245098, 652.7369524265645, 34.94034068627445, 14.880133141762485], [115.26762107843139, 666.8748703703704, 216.80256683006536, 14.880133141762428], [693.4437859477124, 666.8748703703704, 8.712499999999977, 14.880133141762428], [724.3152618464052, 666.7923729246488, 39.47651838235299, 14.915530332056164], [826.415227124183, 666.8748703703704, 6.624933415032615, 14.880133141762428], [853.0852916666666, 666.8748703703704, 37.033316993464155, 14.880133141762428]], 'category_ids': [6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 5, 5, 8, 10, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]}\n",
      "{'texts': ['attention to detail and ability to recognize', 'what makes games compelling.', 'While the success of the', 'Grand Theft', 'Auto', 'franchise is extremely rewarding,', 'creating a blockbuster of this magnitude', 'also affords Take-Two an invaluable base', 'of knowledge and expertise. During fiscal', '2003, Take-Two took significant steps to', 'share and leverage internal resources and', 'experiences to create a more integrated', 'and seamless publishing operation. Our', 'Rockstar Games, Gathering and Global', 'Star Software publishing labels have been', 'streamlined to tap Rockstar’s knowledge,', 'Rockstar’s unique market position is com-', 'plemented by Gathering’s focus on pub-', 'lishing premium and mid-priced products', 'on PC, console and handheld platforms.', 'We firmly believe demand for our premi-', 'um priced games such as', 'Grand Theft', 'Auto, Max Payne, Midnight Club,', 'Manhunt,', 'and', 'Mafia', 'will continue to grow', 'as the installed base of video game plat-', 'forms increases – creating more con-', 'sumers for our products.', 'Global', 'Star', 'Additionally, with gradual reductions in', 'hardware pricing and the resulting', 'increased penetration of video game plat-', 'forms, there is a much greater opportuni-', 'ty to attract a more diverse and, at times,', 'price conscious gamer. Jack of All', 'Games’ success in distributing budget-', 'priced titles has proven that the value', 'segment of the software market is a desir-', 'able long-term business. Accordingly, our', 'Global Star label is publishing games that', 'combine value pricing with compelling', 'game play and is distributing these titles', 'exclusively through Jack of All Games,', 'Global', 'Star Software publishes value-priced', 'entertainment', 'software across all platforms.', 'Cor', 'Global Star franchises include the hit', 'Outlaw', 'sports series (under license from', 'MTV);the', 'Tycoon', 'franchise, including', 'School', 'Tycoon', ',', 'Airport Tycoon 3', 'and', 'Mall Tycoon 2', ';', 'Motocr', 'oss', 'Mania', '; and', 'Army Men', '. In addition', 'to', 'original content, Global Star manages the', 'jewel', 'case and value compilation business for', 'all Take-T', 'wo PC products.', '4'], 'bboxes': [[587.6441515650741, 345.5060293560606, 316.6591264415157, 12.734887310606155], [587.6441515650741, 366.2131000631314, 237.64849588138384, 12.734848484848385], [239.78583196046128, 345.5060293560606, 187.32845963756176, 12.734887310606155], [427.1311610378913, 345.5060293560606, 91.11692751235591, 12.734887310606155], [239.78583196046128, 366.2131000631314, 36.6027837726524, 12.734848484848385], [281.21136738056015, 366.2131000631314, 245.19960502471162, 12.734848484848385], [239.78583196046128, 386.92017077020205, 304.8623896210874, 12.734848484848499], [239.78583196046128, 407.6272414772727, 304.7155292421747, 12.734848484848499], [239.78583196046128, 428.3343121843435, 317.2670510708402, 12.734848484848385], [239.78583196046128, 449.0413828914142, 298.1737327018122, 12.734848484848499], [239.78583196046128, 469.74845359848484, 313.3798187808896, 12.734848484848499], [239.78583196046128, 490.4555243055556, 303.0470926688633, 12.734848484848385], [239.78583196046128, 511.1625950126263, 305.2322001647447, 12.734848484848442], [239.78583196046128, 531.869665719697, 294.46716721581555, 12.734848484848442], [239.78583196046128, 552.5767364267676, 314.97388797364084, 12.734848484848442], [239.78583196046128, 573.2838071338384, 312.74653088962106, 12.734848484848442], [587.6441515650741, 398.5678980429293, 311.15426853377267, 12.734848484848499], [587.6441515650741, 419.2749687500001, 304.6157648270181, 12.734848484848385], [587.6441515650741, 439.98203945707075, 311.8769695222404, 12.734848484848499], [587.6441515650741, 460.6891101641414, 302.4831231466227, 12.734848484848499], [587.6441515650741, 481.3961808712122, 306.57628418451407, 12.734848484848385], [587.6441515650741, 502.1032515782829, 195.77501688632617, 12.734848484848442], [783.4242174629325, 502.1032515782829, 91.11691062602972, 12.734848484848442], [587.6441515650741, 522.8103222853535, 249.75215856672162, 12.734848484848499], [587.6441515650741, 543.5173929924242, 75.70477759472817, 12.734848484848442], [663.7947450576606, 543.5173929924242, 28.460214168039556, 12.734848484848442], [697.0827767710049, 543.5173929924242, 41.58257825370674, 12.734848484848442], [743.4880728995057, 543.5173929924242, 157.09523187808907, 12.734848484848442], [587.6424967051071, 564.224463699495, 306.3990115321251, 12.734848484848442], [587.6424967051071, 584.9315344065657, 276.79564373970345, 12.734848484848442], [587.6424967051071, 605.6386051136365, 184.77355848434922, 12.734848484848442], [159.4759894151565, 633.6891796085858, 60.304274176276806, 18.80717108585867], [208.81585378912683, 633.6891796085858, 71.26868904448105, 18.80717108585867], [587.6424967051071, 637.9934030934344, 292.579208401977, 12.734848484848442], [587.6424967051071, 658.700473800505, 257.8389695222405, 12.734848484848499], [587.6424967051071, 679.4075445075757, 317.4139789950576, 12.734848484848442], [587.6424967051071, 700.1146152146465, 310.69830395387146, 12.734848484848499], [587.6424967051071, 720.8216859217172, 309.69022405271835, 12.734848484848499], [587.6424967051071, 741.528756628788, 259.1155926688633, 12.734848484848499], [587.6424967051071, 762.2358273358586, 293.4236260296541, 12.73484848484847], [587.6424967051071, 782.9428980429293, 283.42849135090603, 12.734848484848499], [587.6424967051071, 803.64996875, 316.1103039538715, 12.73484848484847], [587.6424967051071, 824.3570394570708, 316.47175576606264, 12.734848484848499], [587.6424967051071, 845.0641101641414, 314.3322075782538, 12.734848484848499], [587.6424967051071, 865.7711808712121, 291.29417586490945, 12.734848484848499], [587.6424967051071, 886.4782515782829, 305.23044398682043, 12.734848484848484], [587.6424967051071, 907.1853274621212, 288.0536898682042, 12.734843308080812], [159.4759894151565, 671.3087373737374, 51.74196116144975, 14.008346275252507], [277.0713636738056, 671.3087373737374, 280.59044028006593, 14.008346275252507], [159.4759894151565, 692.0151739267676, 116.65073628500824, 14.008320391414145], [229.46642915980232, 692.0151739267676, 328.2083603789127, 14.008320391414145], [159.4759894151565, 712.7215975378788, 31.568154324546953, 14.008320391414145], [543.8887928336079, 712.7215975378788, 13.76002553542014, 14.008320391414145], [159.4759894151565, 733.42802114899, 64.31021733937399, 14.008320391414145], [236.99671746293245, 733.42802114899, 321.09970675453053, 14.008320391414145], [159.4759894151565, 754.1344318181818, 75.0433857907743, 14.008320391414145], [254.02809719934103, 754.1344318181818, 60.7438303130148, 14.008320391414145], [322.6421544481055, 754.1344318181818, 177.0397899505765, 14.008320391414145], [499.7135387149917, 754.1344318181818, 57.97242957166395, 14.008320391414145], [159.4760147446458, 774.8408554292929, 60.74383369028007, 14.008320391414173], [220.23470840197695, 774.8408554292929, 10.933203871499188, 14.008320391414173], [233.30219192751233, 774.8408554292929, 148.27459184514007, 14.008320391414173], [389.1702438220758, 774.8408554292929, 37.71459637561776, 14.008320391414173], [429.0061173805601, 774.8408554292929, 123.22436861614506, 14.008320391414173], [552.2305366556837, 774.8408554292929, 5.163855436573158, 14.008320391414173], [159.47789588138386, 795.5472790404041, 62.78337429983526, 14.008320391414117], [221.93435090609555, 795.5472790404041, 23.908015238879727, 14.008320391414117], [274.5320148270181, 795.5472790404041, 33.47126523887977, 14.008320391414117], [308.01812314662277, 795.5472790404041, 49.39454736408561, 14.008320391414117], [357.4145111202636, 795.5472790404041, 89.88606630971992, 14.008320391414117], [447.30989868204284, 795.5472790404041, 110.3779777594728, 14.008320391414117], [159.4760654036244, 816.253689709596, 13.57458327841843, 14.008320391414145], [535.0393953871499, 816.253689709596, 22.624316721581636, 14.008320391414145], [159.4760654036244, 836.960113320707, 39.81598484349257, 14.008320391414145], [508.9719060955519, 836.960113320707, 48.66397734761114, 14.008320391414145], [159.4760654036244, 857.666523989899, 82.01216153212519, 14.008333333333297], [239.43383649093906, 857.666523989899, 149.67328624382205, 14.008333333333297], [25.086495057660624, 967.2774873737374, 7.997364085667218, 10.18788137626263]], 'category_ids': [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 5]}\n"
     ]
    }
   ],
   "source": [
    "p = {\n",
    "        \"texts\": [],\n",
    "        \"bboxes\": [],\n",
    "        \"category_ids\": []\n",
    "    }\n",
    "\n",
    "for i, sample in enumerate(ds['train'].take(2)):\n",
    "    try:\n",
    "        result = preprocess_sample(sample)\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing sample {i}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b880971c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': ['attention to detail and ability to recognize',\n",
       "  'what makes games compelling.',\n",
       "  'While the success of the',\n",
       "  'Grand Theft',\n",
       "  'Auto',\n",
       "  'franchise is extremely rewarding,',\n",
       "  'creating a blockbuster of this magnitude',\n",
       "  'also affords Take-Two an invaluable base',\n",
       "  'of knowledge and expertise. During fiscal',\n",
       "  '2003, Take-Two took significant steps to',\n",
       "  'share and leverage internal resources and',\n",
       "  'experiences to create a more integrated',\n",
       "  'and seamless publishing operation. Our',\n",
       "  'Rockstar Games, Gathering and Global',\n",
       "  'Star Software publishing labels have been',\n",
       "  'streamlined to tap Rockstar’s knowledge,',\n",
       "  'Rockstar’s unique market position is com-',\n",
       "  'plemented by Gathering’s focus on pub-',\n",
       "  'lishing premium and mid-priced products',\n",
       "  'on PC, console and handheld platforms.',\n",
       "  'We firmly believe demand for our premi-',\n",
       "  'um priced games such as',\n",
       "  'Grand Theft',\n",
       "  'Auto, Max Payne, Midnight Club,',\n",
       "  'Manhunt,',\n",
       "  'and',\n",
       "  'Mafia',\n",
       "  'will continue to grow',\n",
       "  'as the installed base of video game plat-',\n",
       "  'forms increases – creating more con-',\n",
       "  'sumers for our products.',\n",
       "  'Global',\n",
       "  'Star',\n",
       "  'Additionally, with gradual reductions in',\n",
       "  'hardware pricing and the resulting',\n",
       "  'increased penetration of video game plat-',\n",
       "  'forms, there is a much greater opportuni-',\n",
       "  'ty to attract a more diverse and, at times,',\n",
       "  'price conscious gamer. Jack of All',\n",
       "  'Games’ success in distributing budget-',\n",
       "  'priced titles has proven that the value',\n",
       "  'segment of the software market is a desir-',\n",
       "  'able long-term business. Accordingly, our',\n",
       "  'Global Star label is publishing games that',\n",
       "  'combine value pricing with compelling',\n",
       "  'game play and is distributing these titles',\n",
       "  'exclusively through Jack of All Games,',\n",
       "  'Global',\n",
       "  'Star Software publishes value-priced',\n",
       "  'entertainment',\n",
       "  'software across all platforms.',\n",
       "  'Cor',\n",
       "  'Global Star franchises include the hit',\n",
       "  'Outlaw',\n",
       "  'sports series (under license from',\n",
       "  'MTV);the',\n",
       "  'Tycoon',\n",
       "  'franchise, including',\n",
       "  'School',\n",
       "  'Tycoon',\n",
       "  ',',\n",
       "  'Airport Tycoon 3',\n",
       "  'and',\n",
       "  'Mall Tycoon 2',\n",
       "  ';',\n",
       "  'Motocr',\n",
       "  'oss',\n",
       "  'Mania',\n",
       "  '; and',\n",
       "  'Army Men',\n",
       "  '. In addition',\n",
       "  'to',\n",
       "  'original content, Global Star manages the',\n",
       "  'jewel',\n",
       "  'case and value compilation business for',\n",
       "  'all Take-T',\n",
       "  'wo PC products.',\n",
       "  '4'],\n",
       " 'bboxes': [[587.6441515650741,\n",
       "   345.5060293560606,\n",
       "   316.6591264415157,\n",
       "   12.734887310606155],\n",
       "  [587.6441515650741,\n",
       "   366.2131000631314,\n",
       "   237.64849588138384,\n",
       "   12.734848484848385],\n",
       "  [239.78583196046128,\n",
       "   345.5060293560606,\n",
       "   187.32845963756176,\n",
       "   12.734887310606155],\n",
       "  [427.1311610378913,\n",
       "   345.5060293560606,\n",
       "   91.11692751235591,\n",
       "   12.734887310606155],\n",
       "  [239.78583196046128,\n",
       "   366.2131000631314,\n",
       "   36.6027837726524,\n",
       "   12.734848484848385],\n",
       "  [281.21136738056015,\n",
       "   366.2131000631314,\n",
       "   245.19960502471162,\n",
       "   12.734848484848385],\n",
       "  [239.78583196046128,\n",
       "   386.92017077020205,\n",
       "   304.8623896210874,\n",
       "   12.734848484848499],\n",
       "  [239.78583196046128,\n",
       "   407.6272414772727,\n",
       "   304.7155292421747,\n",
       "   12.734848484848499],\n",
       "  [239.78583196046128,\n",
       "   428.3343121843435,\n",
       "   317.2670510708402,\n",
       "   12.734848484848385],\n",
       "  [239.78583196046128,\n",
       "   449.0413828914142,\n",
       "   298.1737327018122,\n",
       "   12.734848484848499],\n",
       "  [239.78583196046128,\n",
       "   469.74845359848484,\n",
       "   313.3798187808896,\n",
       "   12.734848484848499],\n",
       "  [239.78583196046128,\n",
       "   490.4555243055556,\n",
       "   303.0470926688633,\n",
       "   12.734848484848385],\n",
       "  [239.78583196046128,\n",
       "   511.1625950126263,\n",
       "   305.2322001647447,\n",
       "   12.734848484848442],\n",
       "  [239.78583196046128,\n",
       "   531.869665719697,\n",
       "   294.46716721581555,\n",
       "   12.734848484848442],\n",
       "  [239.78583196046128,\n",
       "   552.5767364267676,\n",
       "   314.97388797364084,\n",
       "   12.734848484848442],\n",
       "  [239.78583196046128,\n",
       "   573.2838071338384,\n",
       "   312.74653088962106,\n",
       "   12.734848484848442],\n",
       "  [587.6441515650741,\n",
       "   398.5678980429293,\n",
       "   311.15426853377267,\n",
       "   12.734848484848499],\n",
       "  [587.6441515650741,\n",
       "   419.2749687500001,\n",
       "   304.6157648270181,\n",
       "   12.734848484848385],\n",
       "  [587.6441515650741,\n",
       "   439.98203945707075,\n",
       "   311.8769695222404,\n",
       "   12.734848484848499],\n",
       "  [587.6441515650741,\n",
       "   460.6891101641414,\n",
       "   302.4831231466227,\n",
       "   12.734848484848499],\n",
       "  [587.6441515650741,\n",
       "   481.3961808712122,\n",
       "   306.57628418451407,\n",
       "   12.734848484848385],\n",
       "  [587.6441515650741,\n",
       "   502.1032515782829,\n",
       "   195.77501688632617,\n",
       "   12.734848484848442],\n",
       "  [783.4242174629325,\n",
       "   502.1032515782829,\n",
       "   91.11691062602972,\n",
       "   12.734848484848442],\n",
       "  [587.6441515650741,\n",
       "   522.8103222853535,\n",
       "   249.75215856672162,\n",
       "   12.734848484848499],\n",
       "  [587.6441515650741,\n",
       "   543.5173929924242,\n",
       "   75.70477759472817,\n",
       "   12.734848484848442],\n",
       "  [663.7947450576606,\n",
       "   543.5173929924242,\n",
       "   28.460214168039556,\n",
       "   12.734848484848442],\n",
       "  [697.0827767710049,\n",
       "   543.5173929924242,\n",
       "   41.58257825370674,\n",
       "   12.734848484848442],\n",
       "  [743.4880728995057,\n",
       "   543.5173929924242,\n",
       "   157.09523187808907,\n",
       "   12.734848484848442],\n",
       "  [587.6424967051071, 564.224463699495, 306.3990115321251, 12.734848484848442],\n",
       "  [587.6424967051071,\n",
       "   584.9315344065657,\n",
       "   276.79564373970345,\n",
       "   12.734848484848442],\n",
       "  [587.6424967051071,\n",
       "   605.6386051136365,\n",
       "   184.77355848434922,\n",
       "   12.734848484848442],\n",
       "  [159.4759894151565,\n",
       "   633.6891796085858,\n",
       "   60.304274176276806,\n",
       "   18.80717108585867],\n",
       "  [208.81585378912683,\n",
       "   633.6891796085858,\n",
       "   71.26868904448105,\n",
       "   18.80717108585867],\n",
       "  [587.6424967051071, 637.9934030934344, 292.579208401977, 12.734848484848442],\n",
       "  [587.6424967051071, 658.700473800505, 257.8389695222405, 12.734848484848499],\n",
       "  [587.6424967051071,\n",
       "   679.4075445075757,\n",
       "   317.4139789950576,\n",
       "   12.734848484848442],\n",
       "  [587.6424967051071,\n",
       "   700.1146152146465,\n",
       "   310.69830395387146,\n",
       "   12.734848484848499],\n",
       "  [587.6424967051071,\n",
       "   720.8216859217172,\n",
       "   309.69022405271835,\n",
       "   12.734848484848499],\n",
       "  [587.6424967051071, 741.528756628788, 259.1155926688633, 12.734848484848499],\n",
       "  [587.6424967051071, 762.2358273358586, 293.4236260296541, 12.73484848484847],\n",
       "  [587.6424967051071,\n",
       "   782.9428980429293,\n",
       "   283.42849135090603,\n",
       "   12.734848484848499],\n",
       "  [587.6424967051071, 803.64996875, 316.1103039538715, 12.73484848484847],\n",
       "  [587.6424967051071,\n",
       "   824.3570394570708,\n",
       "   316.47175576606264,\n",
       "   12.734848484848499],\n",
       "  [587.6424967051071,\n",
       "   845.0641101641414,\n",
       "   314.3322075782538,\n",
       "   12.734848484848499],\n",
       "  [587.6424967051071,\n",
       "   865.7711808712121,\n",
       "   291.29417586490945,\n",
       "   12.734848484848499],\n",
       "  [587.6424967051071,\n",
       "   886.4782515782829,\n",
       "   305.23044398682043,\n",
       "   12.734848484848484],\n",
       "  [587.6424967051071,\n",
       "   907.1853274621212,\n",
       "   288.0536898682042,\n",
       "   12.734843308080812],\n",
       "  [159.4759894151565,\n",
       "   671.3087373737374,\n",
       "   51.74196116144975,\n",
       "   14.008346275252507],\n",
       "  [277.0713636738056,\n",
       "   671.3087373737374,\n",
       "   280.59044028006593,\n",
       "   14.008346275252507],\n",
       "  [159.4759894151565,\n",
       "   692.0151739267676,\n",
       "   116.65073628500824,\n",
       "   14.008320391414145],\n",
       "  [229.46642915980232,\n",
       "   692.0151739267676,\n",
       "   328.2083603789127,\n",
       "   14.008320391414145],\n",
       "  [159.4759894151565,\n",
       "   712.7215975378788,\n",
       "   31.568154324546953,\n",
       "   14.008320391414145],\n",
       "  [543.8887928336079,\n",
       "   712.7215975378788,\n",
       "   13.76002553542014,\n",
       "   14.008320391414145],\n",
       "  [159.4759894151565, 733.42802114899, 64.31021733937399, 14.008320391414145],\n",
       "  [236.99671746293245,\n",
       "   733.42802114899,\n",
       "   321.09970675453053,\n",
       "   14.008320391414145],\n",
       "  [159.4759894151565, 754.1344318181818, 75.0433857907743, 14.008320391414145],\n",
       "  [254.02809719934103,\n",
       "   754.1344318181818,\n",
       "   60.7438303130148,\n",
       "   14.008320391414145],\n",
       "  [322.6421544481055,\n",
       "   754.1344318181818,\n",
       "   177.0397899505765,\n",
       "   14.008320391414145],\n",
       "  [499.7135387149917,\n",
       "   754.1344318181818,\n",
       "   57.97242957166395,\n",
       "   14.008320391414145],\n",
       "  [159.4760147446458,\n",
       "   774.8408554292929,\n",
       "   60.74383369028007,\n",
       "   14.008320391414173],\n",
       "  [220.23470840197695,\n",
       "   774.8408554292929,\n",
       "   10.933203871499188,\n",
       "   14.008320391414173],\n",
       "  [233.30219192751233,\n",
       "   774.8408554292929,\n",
       "   148.27459184514007,\n",
       "   14.008320391414173],\n",
       "  [389.1702438220758,\n",
       "   774.8408554292929,\n",
       "   37.71459637561776,\n",
       "   14.008320391414173],\n",
       "  [429.0061173805601,\n",
       "   774.8408554292929,\n",
       "   123.22436861614506,\n",
       "   14.008320391414173],\n",
       "  [552.2305366556837,\n",
       "   774.8408554292929,\n",
       "   5.163855436573158,\n",
       "   14.008320391414173],\n",
       "  [159.47789588138386,\n",
       "   795.5472790404041,\n",
       "   62.78337429983526,\n",
       "   14.008320391414117],\n",
       "  [221.93435090609555,\n",
       "   795.5472790404041,\n",
       "   23.908015238879727,\n",
       "   14.008320391414117],\n",
       "  [274.5320148270181,\n",
       "   795.5472790404041,\n",
       "   33.47126523887977,\n",
       "   14.008320391414117],\n",
       "  [308.01812314662277,\n",
       "   795.5472790404041,\n",
       "   49.39454736408561,\n",
       "   14.008320391414117],\n",
       "  [357.4145111202636,\n",
       "   795.5472790404041,\n",
       "   89.88606630971992,\n",
       "   14.008320391414117],\n",
       "  [447.30989868204284,\n",
       "   795.5472790404041,\n",
       "   110.3779777594728,\n",
       "   14.008320391414117],\n",
       "  [159.4760654036244, 816.253689709596, 13.57458327841843, 14.008320391414145],\n",
       "  [535.0393953871499,\n",
       "   816.253689709596,\n",
       "   22.624316721581636,\n",
       "   14.008320391414145],\n",
       "  [159.4760654036244, 836.960113320707, 39.81598484349257, 14.008320391414145],\n",
       "  [508.9719060955519, 836.960113320707, 48.66397734761114, 14.008320391414145],\n",
       "  [159.4760654036244, 857.666523989899, 82.01216153212519, 14.008333333333297],\n",
       "  [239.43383649093906,\n",
       "   857.666523989899,\n",
       "   149.67328624382205,\n",
       "   14.008333333333297],\n",
       "  [25.086495057660624,\n",
       "   967.2774873737374,\n",
       "   7.997364085667218,\n",
       "   10.18788137626263]],\n",
       " 'category_ids': [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  8,\n",
       "  8,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  5]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p['texts'].extend(result['texts'])\n",
    "p['bboxes'].extend(result['bboxes'])\n",
    "p['category_ids'].extend(result['category_ids'])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8e7cc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = LayoutLMv3ForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/layoutlmv3-base\",\n",
    "    num_labels=5  # For Caption, Section-header, Text, Title, Other\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c98f7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ;\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n",
      "WARNING:__main__:Skipping empty or invalid text: ,\n"
     ]
    }
   ],
   "source": [
    "t1 = process_dataset(ds['train'], num_samples=200)\n",
    "v1 = process_dataset(ds['val'], num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd6609c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'bbox', 'labels', 'category_ids'])\n",
      "dict_keys(['input_ids', 'attention_mask', 'bbox', 'labels', 'category_ids'])\n"
     ]
    }
   ],
   "source": [
    "print(v1.keys(), t1.keys(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fbc9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(t1)\n",
    "val_dataset = create_dataset(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "482274c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu128\n",
      "True\n",
      "NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fdfb3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20177"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac13b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./layoutlmv3-headings\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,  # Further reduced for 6GB GPU\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,  # Effective batch size = 2 * 4 = 8\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    max_grad_norm=1.0,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73da6a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts: {4: 11407, 2: 8098, 1: 546, 0: 83, 3: 43}\n",
      "Class weights: tensor([48.6193,  7.3908,  0.4983, 93.8465,  0.3538], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:1589: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3150' max='3150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3150/3150 3:22:25, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Classification Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.492500</td>\n",
       "      <td>0.394606</td>\n",
       "      <td>0.876201</td>\n",
       "      <td>{'Caption': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 93.0}, 'Section-header': {'precision': 0.5357142857142857, 'recall': 0.17543859649122806, 'f1-score': 0.2643171806167401, 'support': 171.0}, 'Text': {'precision': 0.790187217559716, 'recall': 0.8583450210378681, 'f1-score': 0.8228571428571428, 'support': 1426.0}, 'Title': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, 'Other': {'precision': 0.916206987128973, 'recall': 0.9378865286367303, 'f1-score': 0.9269200106298167, 'support': 3719.0}, 'accuracy': 0.8762010347376201, 'macro avg': {'precision': 0.44842169808059495, 'recall': 0.3943340292331653, 'f1-score': 0.40281886682073986, 'support': 5412.0}, 'weighted avg': {'precision': 0.854727993390604, 'recall': 0.8762010347376201, 'f1-score': 0.8621226982875159, 'support': 5412.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.452233</td>\n",
       "      <td>0.872875</td>\n",
       "      <td>{'Caption': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 93.0}, 'Section-header': {'precision': 0.5319148936170213, 'recall': 0.29239766081871343, 'f1-score': 0.37735849056603776, 'support': 171.0}, 'Text': {'precision': 0.7625075346594334, 'recall': 0.8870967741935484, 'f1-score': 0.820097244732577, 'support': 1426.0}, 'Title': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, 'Other': {'precision': 0.9316753211259907, 'recall': 0.9166442592094649, 'f1-score': 0.9240986717267552, 'support': 3719.0}, 'accuracy': 0.8728750923872876, 'macro avg': {'precision': 0.44521954988048906, 'recall': 0.41922773884434533, 'f1-score': 0.4243108814050739, 'support': 5412.0}, 'weighted avg': {'precision': 0.8579441445861828, 'recall': 0.8728750923872876, 'f1-score': 0.8630284429096913, 'support': 5412.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.497221</td>\n",
       "      <td>0.883962</td>\n",
       "      <td>{'Caption': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 93.0}, 'Section-header': {'precision': 0.5952380952380952, 'recall': 0.29239766081871343, 'f1-score': 0.39215686274509803, 'support': 171.0}, 'Text': {'precision': 0.816408876933423, 'recall': 0.8513323983169705, 'f1-score': 0.8335049776862341, 'support': 1426.0}, 'Title': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, 'Other': {'precision': 0.9164280135381411, 'recall': 0.9464909922022049, 'f1-score': 0.9312169312169312, 'support': 3719.0}, 'accuracy': 0.8839615668883961, 'macro avg': {'precision': 0.46561499714193183, 'recall': 0.4180442102675778, 'f1-score': 0.4313757543296527, 'support': 5412.0}, 'weighted avg': {'precision': 0.8636697256358318, 'recall': 0.8839615668883961, 'f1-score': 0.871920304675859, 'support': 5412.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>0.597988</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>{'Caption': {'precision': 0.2857142857142857, 'recall': 0.021505376344086023, 'f1-score': 0.04, 'support': 93.0}, 'Section-header': {'precision': 0.5625, 'recall': 0.3157894736842105, 'f1-score': 0.4044943820224719, 'support': 171.0}, 'Text': {'precision': 0.8213538032100488, 'recall': 0.8253856942496494, 'f1-score': 0.8233648128716334, 'support': 1426.0}, 'Title': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, 'Other': {'precision': 0.9081290322580645, 'recall': 0.9462221027157838, 'f1-score': 0.926784303397419, 'support': 3719.0}, 'accuracy': 0.8780487804878049, 'macro avg': {'precision': 0.5155394242364798, 'recall': 0.4217805293987459, 'f1-score': 0.43892869965830494, 'support': 5412.0}, 'weighted avg': {'precision': 0.8631451077081855, 'recall': 0.8780487804878049, 'f1-score': 0.8672796723606417, 'support': 5412.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.660009</td>\n",
       "      <td>0.878234</td>\n",
       "      <td>{'Caption': {'precision': 0.3076923076923077, 'recall': 0.043010752688172046, 'f1-score': 0.07547169811320754, 'support': 93.0}, 'Section-header': {'precision': 0.5714285714285714, 'recall': 0.21052631578947367, 'f1-score': 0.3076923076923077, 'support': 171.0}, 'Text': {'precision': 0.790920716112532, 'recall': 0.8674614305750351, 'f1-score': 0.8274247491638796, 'support': 1426.0}, 'Title': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, 'Other': {'precision': 0.9217714134181915, 'recall': 0.9346598547996773, 'f1-score': 0.9281708945260347, 'support': 3719.0}, 'accuracy': 0.8782335550628233, 'macro avg': {'precision': 0.5183626017303206, 'recall': 0.41113167077047164, 'f1-score': 0.42775192989908595, 'support': 5412.0}, 'weighted avg': {'precision': 0.8651608458995557, 'recall': 0.8782335550628233, 'f1-score': 0.8668531968939261, 'support': 5412.0}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Trainer is attempting to log a value of \"{'Caption': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 93.0}, 'Section-header': {'precision': 0.5357142857142857, 'recall': 0.17543859649122806, 'f1-score': 0.2643171806167401, 'support': 171.0}, 'Text': {'precision': 0.790187217559716, 'recall': 0.8583450210378681, 'f1-score': 0.8228571428571428, 'support': 1426.0}, 'Title': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, 'Other': {'precision': 0.916206987128973, 'recall': 0.9378865286367303, 'f1-score': 0.9269200106298167, 'support': 3719.0}, 'accuracy': 0.8762010347376201, 'macro avg': {'precision': 0.44842169808059495, 'recall': 0.3943340292331653, 'f1-score': 0.40281886682073986, 'support': 5412.0}, 'weighted avg': {'precision': 0.854727993390604, 'recall': 0.8762010347376201, 'f1-score': 0.8621226982875159, 'support': 5412.0}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:1589: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Trainer is attempting to log a value of \"{'Caption': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 93.0}, 'Section-header': {'precision': 0.5319148936170213, 'recall': 0.29239766081871343, 'f1-score': 0.37735849056603776, 'support': 171.0}, 'Text': {'precision': 0.7625075346594334, 'recall': 0.8870967741935484, 'f1-score': 0.820097244732577, 'support': 1426.0}, 'Title': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, 'Other': {'precision': 0.9316753211259907, 'recall': 0.9166442592094649, 'f1-score': 0.9240986717267552, 'support': 3719.0}, 'accuracy': 0.8728750923872876, 'macro avg': {'precision': 0.44521954988048906, 'recall': 0.41922773884434533, 'f1-score': 0.4243108814050739, 'support': 5412.0}, 'weighted avg': {'precision': 0.8579441445861828, 'recall': 0.8728750923872876, 'f1-score': 0.8630284429096913, 'support': 5412.0}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:1589: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Trainer is attempting to log a value of \"{'Caption': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 93.0}, 'Section-header': {'precision': 0.5952380952380952, 'recall': 0.29239766081871343, 'f1-score': 0.39215686274509803, 'support': 171.0}, 'Text': {'precision': 0.816408876933423, 'recall': 0.8513323983169705, 'f1-score': 0.8335049776862341, 'support': 1426.0}, 'Title': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, 'Other': {'precision': 0.9164280135381411, 'recall': 0.9464909922022049, 'f1-score': 0.9312169312169312, 'support': 3719.0}, 'accuracy': 0.8839615668883961, 'macro avg': {'precision': 0.46561499714193183, 'recall': 0.4180442102675778, 'f1-score': 0.4313757543296527, 'support': 5412.0}, 'weighted avg': {'precision': 0.8636697256358318, 'recall': 0.8839615668883961, 'f1-score': 0.871920304675859, 'support': 5412.0}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:1589: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Trainer is attempting to log a value of \"{'Caption': {'precision': 0.2857142857142857, 'recall': 0.021505376344086023, 'f1-score': 0.04, 'support': 93.0}, 'Section-header': {'precision': 0.5625, 'recall': 0.3157894736842105, 'f1-score': 0.4044943820224719, 'support': 171.0}, 'Text': {'precision': 0.8213538032100488, 'recall': 0.8253856942496494, 'f1-score': 0.8233648128716334, 'support': 1426.0}, 'Title': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, 'Other': {'precision': 0.9081290322580645, 'recall': 0.9462221027157838, 'f1-score': 0.926784303397419, 'support': 3719.0}, 'accuracy': 0.8780487804878049, 'macro avg': {'precision': 0.5155394242364798, 'recall': 0.4217805293987459, 'f1-score': 0.43892869965830494, 'support': 5412.0}, 'weighted avg': {'precision': 0.8631451077081855, 'recall': 0.8780487804878049, 'f1-score': 0.8672796723606417, 'support': 5412.0}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:1589: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Trainer is attempting to log a value of \"{'Caption': {'precision': 0.3076923076923077, 'recall': 0.043010752688172046, 'f1-score': 0.07547169811320754, 'support': 93.0}, 'Section-header': {'precision': 0.5714285714285714, 'recall': 0.21052631578947367, 'f1-score': 0.3076923076923077, 'support': 171.0}, 'Text': {'precision': 0.790920716112532, 'recall': 0.8674614305750351, 'f1-score': 0.8274247491638796, 'support': 1426.0}, 'Title': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3.0}, 'Other': {'precision': 0.9217714134181915, 'recall': 0.9346598547996773, 'f1-score': 0.9281708945260347, 'support': 3719.0}, 'accuracy': 0.8782335550628233, 'macro avg': {'precision': 0.5183626017303206, 'recall': 0.41113167077047164, 'f1-score': 0.42775192989908595, 'support': 5412.0}, 'weighted avg': {'precision': 0.8651608458995557, 'recall': 0.8782335550628233, 'f1-score': 0.8668531968939261, 'support': 5412.0}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3150, training_loss=0.3009083567630677, metrics={'train_runtime': 12150.3394, 'train_samples_per_second': 8.303, 'train_steps_per_second': 0.259, 'total_flos': 2.675807028436992e+16, 'train_loss': 0.3009083567630677, 'epoch': 4.999008919722497})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    class_labels = [0, 1, 2, 3, 4]  # All possible class indices\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"classification_report\": classification_report(\n",
    "            labels,\n",
    "            predictions,\n",
    "            labels=class_labels,  # <-- Add this line\n",
    "            target_names=[\"Caption\", \"Section-header\", \"Text\", \"Title\", \"Other\"],\n",
    "            output_dict=True\n",
    "        )\n",
    "    }\n",
    "\n",
    "# Custom Trainer with class weights\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        # Remove keys not expected by the model\n",
    "        if \"category_ids\" in inputs:\n",
    "            inputs.pop(\"category_ids\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Compute class weights\n",
    "label_counts = Counter(train_dataset['labels'])\n",
    "total = sum(label_counts.values())\n",
    "print(\"Label counts:\", dict(label_counts))\n",
    "\n",
    "# Avoid division by zero by adding a small constant\n",
    "class_weights = torch.tensor(\n",
    "    [total / (len(label_counts) * (label_counts.get(i, 0) + 1e-6)) for i in range(5)],\n",
    "    dtype=torch.float\n",
    ").to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ada1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results, metrics\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Test on one document from the test split\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m results, metrics \u001b[38;5;241m=\u001b[39m test_on_document(\u001b[43mtrainer\u001b[49m, ds, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(results, metrics)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "def test_on_document(trainer, dataset, num_samples=1):\n",
    "    # Process one test document\n",
    "    test_processed_data = process_dataset(dataset['test'], num_samples=num_samples)\n",
    "    \n",
    "    # Check if processed data is empty\n",
    "    if not test_processed_data['labels']:\n",
    "        logger.error(\"No valid texts in test_processed_data, cannot proceed\")\n",
    "        return [], {'accuracy': 0.0, 'classification_report': {}}\n",
    "    \n",
    "    test_dataset = create_dataset(test_processed_data)\n",
    "    \n",
    "    # Verify dataset structure\n",
    "    logger.info(\"Verifying test_dataset structure\")\n",
    "    print(\"Sample test_dataset entry:\", test_dataset[0])\n",
    "    \n",
    "    # Debug texts\n",
    "    logger.info(\"Inspecting test_processed_data['labels']\")\n",
    "    print(\"First few texts:\", test_processed_data['labels'][:5])\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    logits = predictions.predictions\n",
    "    predicted_labels = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Ground truth labels\n",
    "    ground_truth_labels = test_dataset['labels']\n",
    "    ground_truth_category_ids = test_dataset['category_ids']\n",
    "    \n",
    "    # Map label indices to names\n",
    "    label_map = {0: \"Caption\", 1: \"Section-header\", 2: \"Text\", 3: \"Title\", 4: \"Other\"}\n",
    "    predicted_labels_named = [label_map[label] for label in predicted_labels]\n",
    "    ground_truth_labels_named = [label_map[label] for label in ground_truth_labels]\n",
    "    \n",
    "    # Extract texts and handle non-string cases\n",
    "    texts = test_processed_data['labels']\n",
    "    formatted_texts = []\n",
    "    for text in texts:\n",
    "        if not isinstance(text, str):\n",
    "            logger.warning(f\"Non-string text found: {text}, converting to string\")\n",
    "            text = str(text)\n",
    "        formatted_texts.append(text)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nTest Document Results:\")\n",
    "    print(f\"{'Text':<60} {'Predicted':<15} {'Ground Truth':<15} {'Category ID':<10}\")\n",
    "    print(\"-\" * 100)\n",
    "    for text, pred, gt, cat_id in zip(formatted_texts, predicted_labels_named, ground_truth_labels_named, ground_truth_category_ids):\n",
    "        print(f\"{text[:57]:<60} {pred:<15} {gt:<15} {cat_id:<10}\")\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = compute_metrics((logits, ground_truth_labels))\n",
    "    print(\"\\nMetrics on Test Document:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    for label, scores in metrics['classification_report'].items():\n",
    "        if isinstance(scores, dict):\n",
    "            print(f\"{label}:\")\n",
    "            print(f\"  Precision: {scores['precision']:.4f}\")\n",
    "            print(f\"  Recall: {scores['recall']:.4f}\")\n",
    "            print(f\"  F1-Score: {scores['f1-score']:.4f}\")\n",
    "            print(f\"  Support: {scores['support']}\")\n",
    "    \n",
    "    # Save results to JSON\n",
    "    results = []\n",
    "    for text, pred, gt, cat_id in zip(formatted_texts, predicted_labels_named, ground_truth_labels_named, ground_truth_category_ids):\n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"predicted_label\": pred,\n",
    "            \"ground_truth_label\": gt,\n",
    "            \"category_id\": int(cat_id)\n",
    "        })\n",
    "    \n",
    "    output_file = \"./test_predictions.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"\\nResults saved to {output_file}\")\n",
    "    \n",
    "    return results, metrics\n",
    "\n",
    "# Test on one document from the test split\n",
    "results, metrics = test_on_document(trainer, ds, num_samples=1)\n",
    "print(results, metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
